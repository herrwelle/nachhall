<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Nachhall · 扫描播放</title>
<style>
  :root{color-scheme:dark}
  html,body{margin:0;height:100%;background:#000;color:#eaffff;font-family:system-ui,-apple-system,Segoe UI}
  #stage{position:fixed;inset:0;display:grid;place-items:center;background:#000}
  video{max-width:100vw;max-height:100vh;display:block;opacity:.98}
  #ui{position:fixed;left:0;top:0;width:100vw;height:100vh;pointer-events:none}
  #frame{position:fixed;inset:0;pointer-events:none}
  .white{box-shadow:0 0 0 3px rgba(255,255,255,.65) inset}
  .green{box-shadow:0 0 0 4px rgba(0,255,170,.95) inset}
</style>
</head>
<body>
<div id="stage"><video id="cam" playsinline autoplay muted></video></div>
<canvas id="ui"></canvas>
<div id="frame" class="white"></div>

<script>
/* === 与编码页完全一致的参数（不要改） === */
const SR=16000, NFFT=1024, HOP=512;
const K = NFFT/2 + 1;           // 513
const T = 500;                  // 16s → 500 帧
const ENC_MARGIN = 160;         // 版面内边距（像素）
const CELLX = 3, CELLY = 3;
const DBMIN = -80;              // dB floor
const GRID_W = 2*ENC_MARGIN + T*CELLX;
const GRID_H = 2*ENC_MARGIN + K*CELLY;

const cam = document.getElementById('cam');
const ui = document.getElementById('ui');
const frame = document.getElementById('frame');

let capCv=null, capCtx=null;
let lastRect=null, lastSeenTs=0;
let actx=null, buffer=null, source=null, playing=false, durSec=0;
let playStart=0, playOffset=0;

/* ========== 相机启动 ========== */
async function startCam(){
  const s = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}});
  cam.srcObject = s; await cam.play();
  capCv = document.createElement('canvas');
  capCv.width  = cam.videoWidth  || 1280;
  capCv.height = cam.videoHeight || 720;
  capCtx = capCv.getContext('2d',{willReadFrequently:true});
}
function lumAt(d,i){ return 0.2126*d[i]+0.7152*d[i+1]+0.0722*d[i+2]; }

/* ========== 更宽松、稳健的黑框检测 ==========
   思路：从四边向内做“暗像素比例”投影，找到四条边；不再要求长时间稳定，
   只要四边都能找出来（且尺寸/纵横比大致合理）就视为命中，立即绿框。
================================================ */
function findBlackRect(img,W,H){
  const data=img.data;
  const thr = autoThreshold(data, W, H); // 自适应亮度阈值
  const step=2;
  const col=new Float32Array(W), row=new Float32Array(H);

  for(let x=0;x<W;x++){
    let dark=0,tot=0;
    for(let y=0;y<H;y+=step){ const i=(y*W+x)*4; if(lumAt(data,i)<thr) dark++; tot++; }
    col[x]=dark/Math.max(1,tot);
  }
  for(let y=0;y<H;y++){
    let dark=0,tot=0;
    for(let x=0;x<W;x+=step){ const i=(y*W+x)*4; if(lumAt(data,i)<thr) dark++; tot++; }
    row[y]=dark/Math.max(1,tot);
  }

  // 从左右两侧找连续超过阈值的台阶边缘
  const EDGE=0.18; // 暗比例阈值（放宽）
  let xL=0; while(xL<W && col[xL]<EDGE) xL++;
  let xR=W-1; while(xR>=0 && col[xR]<EDGE) xR--;
  let yT=0; while(yT<H && row[yT]<EDGE) yT++;
  let yB=H-1; while(yB>=0 && row[yB]<EDGE) yB--;

  if(xR-xL<100 || yB-yT<100) return null;

  // 纵横比粗验，允许透视误差（0.5~3 倍）
  const ar = (xR-xL)/(yB-yT);
  if(ar<0.5 || ar>3.0) return null;

  return {sx:xL, sy:yT, sw:xR-xL+1, sh:yB-yT+1};
}

/* 自适应阈值：用随机采样的亮度 30% 分位做阈值 */
function autoThreshold(data,W,H){
  const N=600, arr=new Float32Array(N);
  for(let i=0;i<N;i++){
    const x=(Math.random()*W)|0, y=(Math.random()*H)|0, idx=(y*W+x)*4;
    arr[i]=lumAt(data,idx);
  }
  arr.sort(); const p=arr[(N*0.30)|0];
  return Math.max(30, Math.min(160, p));
}

/* ========== 从相机帧“按编码几何”采样为幅度谱（加对比度拉伸+平滑） ========== */
function percentile(arr, p){
  const i = Math.max(0, Math.min(arr.length-1, Math.floor(p*(arr.length-1))));
  return arr[i];
}

function sampleMFromRect(img,W,H,rect){
  const data = img.data;
  const M = new Float32Array(K*T);

  // 标准网格 → 相机像素 线性映射
  const sX = rect.sw / GRID_W;
  const sY = rect.sh / GRID_H;

  // 收集 ROI 亮度用于自适应对比度
  const samp = [];
  for(let i=0;i<800;i++){
    const gx = ENC_MARGIN + Math.random()*(T*CELLX);
    const gy = ENC_MARGIN + Math.random()*(K*CELLY);
    const px = rect.sx + sX*gx, py = rect.sy + sY*gy;
    const xi = Math.max(0, Math.min(W-1, px|0));
    const yi = Math.max(0, Math.min(H-1, py|0));
    const idx = (yi*W + xi)*4;
    samp.push(lumAt(data,idx));
  }
  samp.sort((a,b)=>a-b);
  const p10 = percentile(samp, 0.10);
  const p90 = percentile(samp, 0.90);
  const denom = Math.max(8, p90 - p10);

  // 采样 + 自适应拉伸 + 轻微 3x3 平滑
  for(let t=0;t<T;t++){
    const gx = ENC_MARGIN + t*CELLX + (CELLX>>1);
    const px = rect.sx + sX*gx;
    for(let r=0;r<K;r++){
      const gy = ENC_MARGIN + (K-1-r)*CELLY + (CELLY>>1);
      const py = rect.sy + sY*gy;
      let acc=0, cnt=0; // 3x3
      for(let dy=-1; dy<=1; dy++){
        for(let dx=-1; dx<=1; dx++){
          const xi = Math.max(0, Math.min(W-1, (px+dx)|0));
          const yi = Math.max(0, Math.min(H-1, (py+dy)|0));
          const idx = (yi*W + xi)*4;
          acc += lumAt(data,idx); cnt++;
        }
      }
      const lum = acc/cnt;
      let norm = (p90 - lum) / denom;   // 黑→1，白→0（拉伸）
      norm = Math.max(0, Math.min(1, norm));
      const db = DBMIN + norm*(0-DBMIN);
      M[t*K + r] = Math.pow(10, db/20);
    }
  }
  return M;
}

/* ========== 小型 FFT/IFFT + Griffin–Lim（迭代 28，带 OLA 归一） ========== */
function hann(N){ const w=new Float32Array(N); for(let n=0;n<N;n++) w[n]=0.5*(1-Math.cos(2*Math.PI*n/(N-1))); return w; }
const WIN = hann(NFFT);
function makeFFT(N){
  if(N&(N-1)) throw new Error('N must be pow2');
  const cos=new Float32Array(N/2),sin=new Float32Array(N/2);
  for(let i=0;i<N/2;i++){ const a=-2*Math.PI*i/N; cos[i]=Math.cos(a); sin[i]=Math.sin(a); }
  const rev=new Uint32Array(N); let b=0; while((1<<b)<N) b++;
  for(let i=0;i<N;i++){ let x=i,y=0; for(let j=0;j<b;j++){ y=(y<<1)|(x&1); x>>=1; } rev[i]=y; }
  function fft(re,im){
    for(let i=0;i<N;i++){ const j=rev[i]; if(j>i){ let t=re[i]; re[i]=re[j]; re[j]=t; t=im[i]; im[i]=im[j]; im[j]=t; } }
    for(let len=2; len<=N; len<<=1){ const h=len>>>1, step=N/len;
      for(let i=0;i<N;i+=len) for(let k=0;k<h;k++){
        const c=cos[k*step], s=sin[k*step], j=i+k, l=j+h;
        const r=c*re[l]-s*im[l], ii=s*re[l]+c*im[l];
        re[l]=re[j]-r; im[l]=im[j]-ii; re[j]+=r; im[j]+=ii;
      }
    }
  }
  function ifft(re,im){ for(let i=0;i<N;i++) im[i]=-im[i]; fft(re,im); const inv=1/N; for(let i=0;i<N;i++){ re[i]*=inv; im[i]*=-im[i]; } }
  return {fft,ifft};
}
const FFT = makeFFT(NFFT);

async function griffinLim(M, iters=28){
  const re=new Float32Array(NFFT), im=new Float32Array(NFFT);
  const re2=new Float32Array(NFFT), im2=new Float32Array(NFFT);
  const phase=new Float32Array(K*T); for(let i=0;i<phase.length;i++) phase[i]=Math.random()*2*Math.PI;

  // 预计算 OLA 归一权重（WIN^2 累加）
  const L=(T-1)*HOP + NFFT;
  const y=new Float32Array(L);
  const wsum=new Float32Array(L);
  for(let t=0;t<T;t++){
    const off=t*HOP;
    for(let n=0;n<NFFT;n++){ wsum[off+n] += WIN[n]*WIN[n]; }
  }

  for(let it=0; it<iters; it++){
    y.fill(0);
    for(let t=0;t<T;t++){
      // 频谱幅度 + 当前相位
      for(let k=0;k<K;k++){ const mag=M[t*K+k]; re[k]=mag*Math.cos(phase[t*K+k]); im[k]=mag*Math.sin(phase[t*K+k]); }
      for(let k=K;k<NFFT;k++){ re[k]=0; im[k]=0; }
      for(let k=1;k<K-1;k++){ re[NFFT-k]=re[k]; im[NFFT-k]=-im[k]; }
      FFT.ifft(re,im);
      const off=t*HOP;
      for(let n=0;n<NFFT;n++){ y[off+n] += re[n]*WIN[n]; }
    }
    // OLA 归一，避免能量被窗叠加吃掉低频
    for(let i=0;i<L;i++){ if(wsum[i]>1e-9) y[i] /= wsum[i]; }
    if(it<iters-1){
      // 重新估计相位
      for(let t=0;t<T;t++){
        const off=t*HOP;
        for(let n=0;n<NFFT;n++){ re2[n]=(y[off+n]||0)*WIN[n]; im2[n]=0; }
        FFT.fft(re2,im2);
        for(let k=0;k<K;k++) phase[t*K+k]=Math.atan2(im2[k],re2[k]);
      }
    }
    await new Promise(r=>setTimeout(r,0));
  }
  // 轻限幅
  let peak=1e-9; for(let i=0;i<y.length;i++) peak=Math.max(peak,Math.abs(y[i]));
  const g=0.95/peak; for(let i=0;i<y.length;i++) y[i]=Math.tanh(y[i]*g);
  return y;
}

/* ========== 播放控制（原速循环） ========== */
function stopSource(){ try{ source && source.stop(0); }catch(_){} source=null; playing=false; }
async function ensureAudio(){
  if(!actx) actx=new (window.AudioContext||window.webkitAudioContext)({sampleRate:SR});
  if(actx.state==='suspended'){ try{ await actx.resume(); }catch(_){} }
  return actx.state==='running';
}
function playBuffer(y){
  stopSource();
  const buf = actx.createBuffer(1, y.length, SR);
  buf.getChannelData(0).set(y);
  buffer=buf; durSec = y.length/SR;
  source = actx.createBufferSource();
  source.buffer = buffer; source.loop = true;
  source.connect(actx.destination);
  playOffset = 0;
  playStart = actx.currentTime;
  source.start(0);
  playing=true;
}

/* ========== 取景主循环：只要框在画面里就绿并自动播；离开0.5s暂停 ========== */
let debounceRebuild=0;
async function loop(){
  const W=capCv.width, H=capCv.height;
  capCtx.drawImage(cam,0,0,W,H);
  const img = capCtx.getImageData(0,0,W,H);
  const rect = findBlackRect(img,W,H);

  const now=performance.now();
  const hasRect = !!rect;
  if(hasRect){ lastSeenTs = now; frame.className='green'; }
  else{ frame.className='white'; }

  // 只要看到框，就尝试播放（同一位置 300ms 内不重复重建）
  if(hasRect){
    const moved = !lastRect || Math.abs(rect.sx - lastRect.sx)>6 || Math.abs(rect.sy-lastRect.sy)>6 || Math.abs(rect.sw-lastRect.sw)>10 || Math.abs(rect.sh-lastRect.sh)>10;
    lastRect = rect;
    if(moved || (now - debounceRebuild > 1500) || !playing){
      debounceRebuild = now;
      if(await ensureAudio()){
        const M = sampleMFromRect(img,W,H,rect);
        const y = await griffinLim(M, 28);  // 提升迭代次数，音质更稳
        playBuffer(y);
      }
    }
  }else{
    // 离开画面 0.5s 后暂停
    if(playing && now - lastSeenTs > 500){ stopSource(); }
  }

  drawUIOverlay(rect); // 画播放指示线
  requestAnimationFrame(loop);
}

/* ========== UI 叠加层：播放竖线（映射到相机坐标） ========== */
function drawUIOverlay(rect){
  const ctx = ui.getContext('2d');
  const W = ui.width = innerWidth;
  const H = ui.height = innerHeight;
  ctx.clearRect(0,0,W,H);
  if(!playing || !buffer || !rect) return;

  // 把“当前播放时间”换算成标准网格的列，再映射到相机像素，再映射到屏幕像素画线
  const now = actx.currentTime;
  const t = ((now - playStart + playOffset) % durSec);
  const col = Math.min(T-1, Math.max(0, Math.round((t/durSec)*T)));

  // rect 在相机像素；把它转换到屏幕像素
  const vRect = cam.getBoundingClientRect();
  const sx = vRect.width / capCv.width;
  const sy = vRect.height / capCv.height;
  const ox = vRect.left, oy = vRect.top;

  // 标准网格列中心 → 相机像素
  const sX = rect.sw / GRID_W;
  const gx = ENC_MARGIN + col*CELLX + (CELLX>>1);
  const px = rect.sx + sX*gx;

  // 相机像素 → 屏幕像素
  const screenX = Math.round(ox + px * sx);

  ctx.strokeStyle='rgba(255,255,255,.95)';
  ctx.lineWidth = 2;
  ctx.beginPath();
  ctx.moveTo(screenX, oy);
  ctx.lineTo(screenX, oy + vRect.height);
  ctx.stroke();
}

/* ========== 启动 ========== */
(async ()=>{
  try{
    await startCam();
    loop();
  }catch(e){
    alert('相机启动失败：请在 HTTPS（如 GitHub Pages）下访问并允许相机权限。');
  }
})();
</script>
</body>
</html>
