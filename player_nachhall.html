<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"/>
<title>Nachhall · 声轨播放</title>
<style>
  :root{color-scheme:dark}
  html,body{margin:0;height:100%;background:#000;color:#eaffff;font-family:system-ui,-apple-system,Segoe UI}
  #stage{position:fixed;inset:0;display:grid;place-items:center;background:#000}
  video{max-width:100vw;max-height:100vh;display:block;opacity:.98}
  #ui{position:fixed;left:0;top:0;width:100vw;height:100vh;pointer-events:none}
  #frame{position:fixed;inset:0;pointer-events:none}
  .white{box-shadow:0 0 0 3px rgba(255,255,255,.65) inset}
  .green{box-shadow:0 0 0 4px rgba(0,255,170,.95) inset}
</style>
</head>
<body>
<div id="stage"><video id="cam" playsinline autoplay muted></video></div>
<canvas id="ui"></canvas>
<div id="frame" class="white"></div>

<script>
/* 与编码页一致的几何常量 */
const SR=8000, DUR=16.0, COLS=1600;
const MARGIN=160, TRACK_H=900, TC_W=120, GAP=40, VA_W=1600;
const FRAME_W = TC_W + GAP + VA_W, FRAME_H = TRACK_H;

/* DOM */
const cam=document.getElementById('cam');
const ui=document.getElementById('ui');
const frame=document.getElementById('frame');

let capCv=null, capCtx=null;
let lastRect=null, lastSeenTs=0;
let actx=null, node=null, playing=false;
let amps=null;         // 每列振幅（编码端 A[c]）
let vaRect=null;       // 当前帧中声轨区域在相机像素坐标的矩形
let startT=0;          // 播放起始时间（audio time）
let pauseOffset=0;     // 暂停时的偏移（列）

/* 相机启动 */
async function startCam(){
  const s = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}});
  cam.srcObject=s; await cam.play();
  capCv=document.createElement('canvas');
  capCv.width=cam.videoWidth||1280; capCv.height=cam.videoHeight||720;
  capCtx=capCv.getContext('2d',{willReadFrequently:true});
}

/* 黑框检测（放宽：只要四边能大致找到就算命中） */
function lumAt(d,i){ return 0.2126*d[i]+0.7152*d[i+1]+0.0722*d[i+2]; }
function autoThr(data,W,H){
  const N=600, arr=new Float32Array(N);
  for(let i=0;i<N;i++){ const x=(Math.random()*W)|0,y=(Math.random()*H)|0,idx=(y*W+x)*4; arr[i]=lumAt(data,idx); }
  arr.sort(); return Math.max(30, Math.min(160, arr[(N*0.30)|0]));
}
function findFrameRect(img,W,H){
  const data=img.data, thr=autoThr(data,W,H), step=2;
  const col=new Float32Array(W), row=new Float32Array(H);
  for(let x=0;x<W;x++){ let dark=0,tot=0; for(let y=0;y<H;y+=step){ if(lumAt(data,(y*W+x)*4)<thr) dark++; tot++; } col[x]=dark/Math.max(1,tot); }
  for(let y=0;y<H;y++){ let dark=0,tot=0; for(let x=0;x<W;x+=step){ if(lumAt(data,(y*W+x)*4)<thr) dark++; tot++; } row[y]=dark/Math.max(1,tot); }
  const EDGE=0.18;
  let xL=0; while(xL<W && col[xL]<EDGE) xL++;
  let xR=W-1; while(xR>=0 && col[xR]<EDGE) xR--;
  let yT=0; while(yT<H && row[yT]<EDGE) yT++;
  let yB=H-1; while(yB>=0 && row[yB]<EDGE) yB--;
  if(xR-xL<100 || yB-yT<100) return null;
  const ar=(xR-xL)/(yB-yT);
  if(ar<0.5 || ar>3.0) return null;
  return {sx:xL, sy:yT, sw:xR-xL+1, sh:yB-yT+1};
}
function sameRect(a,b){ if(!a||!b) return false;
  return Math.abs(a.sx-b.sx)<8 && Math.abs(a.sy-b.sy)<8 && Math.abs(a.sw-b.sw)<12 && Math.abs(a.sh-b.sh)<12;
}

/* 从当前帧里“直接读取”声轨列振幅（不截图、不锁屏） */
function readAmpsFromFrame(img,W,H,rect){
  // 标准网格 → 相机像素的线性映射（只做缩放，避免透视引入复杂度）
  const sX = rect.sw / (FRAME_W);
  const sY = rect.sh / (FRAME_H);

  // 声轨在相机像素中的矩形
  const vx = rect.sx + sX*(MARGIN + TC_W + GAP);
  const vy = rect.sy + sY*(MARGIN);
  const vw = sX*(VA_W);
  const vh = sY*(TRACK_H);
  vaRect = {x:vx, y:vy, w:vw, h:vh};

  // 多条垂直样条平均，得到每列的“半宽”→ 映射回振幅
  const data=img.data;
  const stripes=7; const stripeStep = vh*0.9/stripes; const mid = vy + vh/2; const stripeTop = mid - (stripes/2)*stripeStep + stripeStep*0.5;
  const colW = vw / COLS;
  const A=new Float32Array(COLS);

  // 亮度 → 黑度（0~1），自适应拉伸
  // 先采样若干点估算 10%/90% 分位
  const samp=[];
  for(let i=0;i<600;i++){
    const px=vx + Math.random()*vw;
    const py=vy + Math.random()*vh;
    const xi=Math.max(0,Math.min(W-1,px|0)), yi=Math.max(0,Math.min(H-1,py|0));
    const idx=(yi*W+xi)*4; samp.push(lumAt(data,idx));
  }
  samp.sort((a,b)=>a-b); const p10=samp[(samp.length*0.10)|0], p90=samp[(samp.length*0.90)|0];
  const denom=Math.max(8, p90-p10);

  for(let c=0;c<COLS;c++){
    const x0 = vx + c*colW + colW*0.5;
    // 在 x0 处，向上/向下扫描“黑色半宽”
    let halfAcc=0;
    for(let s=0;s<stripes;s++){
      const baseY = stripeTop + s*stripeStep;
      // 自上向下找第一处“黑→白”过渡，粗略估半宽；简化起见用固定步长抽样累加黑度
      const span = Math.floor(vh*0.45);
      let up=0,down=0, cnt=0;
      for(let dy=1; dy<span; dy+=2){
        const y1 = baseY - dy, y2 = baseY + dy;
        const xi=Math.max(0,Math.min(W-1,x0|0));
        const yi1=Math.max(0,Math.min(H-1,y1|0));
        const yi2=Math.max(0,Math.min(H-1,y2|0));
        const idx1=(yi1*W+xi)*4, idx2=(yi2*W+xi)*4;
        const lum1=lumAt(data,idx1), lum2=lumAt(data,idx2);
        // 拉伸成黑度
        const blk1 = Math.max(0, Math.min(1, (p90 - lum1)/denom));
        const blk2 = Math.max(0, Math.min(1, (p90 - lum2)/denom));
        up += blk1; down += blk2; cnt++;
      }
      const half = ((up+down)/Math.max(1,cnt)); // 平均黑度当作半宽指标
      halfAcc += half;
    }
    const halfAvg = halfAcc/stripes;
    // 映射：黑度越大 → 半宽越大 → 振幅越大
    const a = Math.max(-1, Math.min(1, (halfAvg - 0.1) / 0.9 * 1.6 - 0.8)); // 调整为 [-1,1]，经验映射
    A[c]=a;
  }
  // 平滑一下列振幅，减少抖动
  for(let i=1;i<COLS-1;i++) A[i]=(A[i-1]+A[i]+A[i+1])/3;
  return A;
}

/* 声音：AudioWorklet 从列振幅插值出 8kHz 波形，并做去加重（de-emphasis） */
async function ensureAudio(){
  if(actx) return;
  actx=new (window.AudioContext||window.webkitAudioContext)({sampleRate:SR});
  const code=`
    class VAPlayer extends AudioWorkletProcessor{
      constructor(){ super(); this.cols=null; this.colsN=0; this.phase=0; this.running=false;
        this.pre=0.85; this.deY=0; // de-emphasis
        this.port.onmessage=e=>{
          const m=e.data;
          if(m.t==='cols'){ this.cols=m.cols; this.colsN=this.cols.length; }
          else if(m.t==='play'){ this.phase=m.off||0; this.running=true; }
          else if(m.t==='stop'){ this.running=false; }
        };
      }
      process(inputs, outputs, params){
        const out=outputs[0][0];
        if(!this.running || !this.colsN){ out.fill(0); return true; }
        // 每输出样本推进多少“列”：列分辨率 = DUR/COLS（10ms 一列），采样率 SR → 每样本推进 (COLS/DUR)/SR = COLS/(DUR*SR) 列
        const step = this.colsN / ( ${DUR} * ${SR} ); // = 1600/(16*8000)=0.0125 列/样本（即 80 样本/列）
        let ph=this.phase;
        for(let n=0;n<out.length;n++){
          const i0=Math.floor(ph), i1=(i0+1)%this.colsN, a=ph-i0;
          let s = (this.cols[i0]*(1-a) + this.cols[i1]*a);
          // 去加重：简化为一阶 IIR：x[n] = y[n] + PRE*y[n-1] ⇒ y[n] = x[n] - PRE*y[n-1]
          const y = s + this.pre * this.deY; // 近似逆滤（稳定起见用 +）
          this.deY = y;
          out[n] = Math.tanh(y*0.9);
          ph += step;
          if(ph>=this.colsN) ph-=this.colsN;
        }
        this.phase=ph;
        return true;
      }
    }
    registerProcessor('va-player', VAPlayer);
  `;
  const blob=new Blob([code],{type:'application/javascript'});
  const url=URL.createObjectURL(blob);
  await actx.audioWorklet.addModule(url);
  URL.revokeObjectURL(url);
  node=new AudioWorkletNode(actx,'va-player',{numberOfInputs:0,numberOfOutputs:1,outputChannelCount:[1]});
  node.connect(actx.destination);
}
async function playCols(cols, offsetCol=0){
  await ensureAudio();
  if(actx.state==='suspended'){ try{ await actx.resume(); }catch(_){} }
  node.port.postMessage({t:'cols', cols});
  node.port.postMessage({t:'play', off:offsetCol});
  playing=true; startT=actx.currentTime; pauseOffset=offsetCol;
}
function stopPlay(){
  if(node){ node.port.postMessage({t:'stop'}); }
  playing=false; pauseOffset=0;
}

/* 主循环：只要识别到黑框就读取声轨并播放；离开≥0.5s 暂停 */
let lastRebuild=0;
async function loop(){
  const W=capCv.width,H=capCv.height;
  capCtx.drawImage(cam,0,0,W,H);
  const img=capCtx.getImageData(0,0,W,H);
  const rect=findFrameRect(img,W,H);
  const now=performance.now();

  if(rect){ lastSeenTs=now; frame.className='green'; }
  else{ frame.className='white'; }

  if(rect){
    const moved = !lastRect || !sameRect(rect,lastRect);
    lastRect=rect;
    if(moved || (now-lastRebuild>1500) || !playing){
      lastRebuild=now;
      // 从当前帧直接读取列振幅
      amps = readAmpsFromFrame(img,W,H,rect);
      // 若正在播，尽量保持相位连贯：估算此刻列偏移
      let offCol=0;
      if(playing){
        const t = actx.currentTime - startT;
        const col = ((t / DUR) * COLS + pauseOffset) % COLS;
        offCol = col;
      }
      playCols(amps, offCol);
    }
  }else{
    if(playing && now-lastSeenTs>500){ stopPlay(); }
  }

  drawOverlay(rect);
  requestAnimationFrame(loop);
}

/* 叠加层：播放竖线（按 1× 原速在当前 rect 上移动） */
function drawOverlay(rect){
  const ctx=ui.getContext('2d');
  ui.width=innerWidth; ui.height=innerHeight;
  ctx.clearRect(0,0,ui.width,ui.height);
  if(!rect || !playing) return;

  // 当前播放对应的列
  const t = (actx.currentTime - startT);
  let col = ((t / DUR) * COLS + pauseOffset) % COLS;
  if(col<0) col += COLS;

  // 将列映射到相机像素，再到屏幕像素
  const vRect = cam.getBoundingClientRect();
  const sx = vRect.width / capCv.width;
  const sy = vRect.height / capCv.height;
  const ox = vRect.left, oy = vRect.top;

  const sX = rect.sw / (FRAME_W);
  const sY = rect.sh / (FRAME_H);
  const vx = rect.sx + sX*(MARGIN + TC_W + GAP);
  const vy = rect.sy + sY*(MARGIN);
  const vw = sX*(VA_W);
  const vh = sY*(TRACK_H);

  const xCam = vx + (col/COLS)*vw;
  const xScr = Math.round(ox + xCam*sx);
  const yTop = oy + vy*sy;
  const yBot = oy + (vy+vh)*sy;

  ctx.strokeStyle='rgba(255,255,255,.95)';
  ctx.lineWidth=2;
  ctx.beginPath(); ctx.moveTo(xScr, yTop); ctx.lineTo(xScr, yBot); ctx.stroke();
}

/* 启动 */
(async ()=>{
  try{
    await startCam();
    loop();
  }catch(e){
    alert('相机启动失败：请在 HTTPS（GitHub Pages）下访问并允许相机权限。');
  }
})();
</script>
</body>
</html>
